{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Curve fitting is one of the most powerful tools available to us in modern computing. Curve fitting describes the process of matching multiple data points with an equation while finding terms to describe the margins of error and other unknown parameters. </p> <p>In this lesson, we're going to use curve fitting along with gamma spectroscopy data taken at the University of Colorado Denver in order to demonstrate the usefulness of the operation. The data will include 6 radioactive isotopes with known emission spectra as well as a 7th and final unknown isotope. In the process, we will learn how to create a function which can fit a Gaussian curve before using the findings from our fits to find a final line which can help us determine the properties of the unknown isotope. We will also then learn about \\(\\chi^2\\)-fits and use one to determine how well our data fits the solution we find for the unknown isotope.</p> <p>Let's get started - click here to continue on to the next section where we will begin setting up our computers.</p>"},{"location":"01_setup/","title":"Setup","text":"<p>This lesson will be using Python 3 along with several of its more common libraries: <code>scipy</code>, <code>pandas</code>, <code>matplotlib</code>, and <code>numpy</code>. This lesson will also be done using a Jupyter Notebook. </p> <p>First, it'll be necessary to install Python if you don't already have it. You can follow the instructions from python's official website in order to get started. </p> <p>It's recommended to install Jupyter Notebook through <code>pip</code>, so after installing Python you should check that it comes with <code>pip</code> installed. This can be done by running the following commands depending on your operating system:</p> Linux MacOS Windows Command (Check python) python --version python --version py --version Output Python 3.N.N Python 3.N.N Python 3.N.N Command (Check pip) python -m pip --version python -m pip --version py -m pip --version Output pip X.Y.Z from (python 3.N.N) pip X.Y.Z from (python 3.N.N) pip X.Y.Z from (python 3.N.N) <p>You can then use <code>pip</code> to install either <code>JupyterLab</code> or <code>Jupyter Notebook</code> with the command:</p> <pre><code>pip install jupyterlab\n</code></pre> <p>or:</p> <pre><code>pip install notebook\n</code></pre> <p>You can then run them with either:</p> <pre><code>jupyter lab\n</code></pre> <p>or:</p> <pre><code>jupyter notebook\n</code></pre> <p>It should be noted that in order for Jupyter to work you will also be required to have an up-to-date browser. Chrome, Safari, and Firefox are all supported.</p> <p>Running one of these commands will then open Jupyter in a browser. </p> <p>Jupyter will then show you an in-browser version of your file-explorer where you can navigate to create a new project folder to follow along with this lesson. Before doing that, make sure that you also have the necessary libraries installed. Click on <code>New</code> and select <code>Terminal</code> in order to ensure that the libraries are installed in the same location that Jupyter has access to. From this terminal, run the commands:</p> <pre><code>pip install scipy\npip install pandas\npip install matplotlib\npip install numpy\n</code></pre> <p>The <code>scipy</code> library will be used to find our peaks and create our curve fits, <code>pandas</code> will be used for loading the <code>.csv</code> data, <code>matplotlib</code> will be used to plot the data, and <code>numpy</code> will be used for multiple mathematical expressions.</p> <p>Next, create a folder to house your project files, named something like \"data-fitting\". After doing this, download and unzip these raw data files. Then, you can move the \"raw-data\" folder into your project folder. </p> <p>Finally, create a new notebook by clicking on <code>New</code> and <code>Notebook</code> and selecting the kernel - <code>Python 3 (ipykernel)</code>. You can then either name your project or keep it untitled.</p> <p>Now that we're all setup, click here to continue to the next section where we can begin to learn more about the experiment and how it functions before getting started fitting our data.</p>"},{"location":"02_experiment_details/","title":"The Experiment","text":"<p>In this experiment, gamma spectroscopy data was collected from a UCDenver gamma spectroscopy lab. The lab involved taking data using a spectrometer which is fed from a scintillator and a photomultiplier tube (PMT) to record the energy levels emitted by various radioactive sources. Let's go over the types of radioactive decay and describe what the related instruments are doing so that you can have a better understanding of the data that we're looking at when we start plotting it.</p>"},{"location":"02_experiment_details/#radioactive-decay","title":"Radioactive Decay","text":"<p>There are three main types of radioactive decay associated with emissions, alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), and gamma (\\(\\gamma\\)), named in increasing order of their ability to penetrate matter (\\(\\gamma &gt; \\beta &gt; \\alpha\\)). These three types of emissions are notable also for their ability to be separated from each other from inside of an electromagnetic field - meaning they all have different types of charge. </p> <p>Starting from the element bismuth, every element and every isotope is at least slightly radioactive. In other words, there are no stable isotopes after bismuth. From bismuth up, the strong force which holds the nucleus together struggles to reach across the distance of the nucleus, meaning the electric force which wants the positively charged protons to repel each other causes the nucleus to become unstable. For elements lighter than bismuth, every element has at least one stable isotope, but there are still many unstable isotopes such as Carbon-14 or Potassium-40.</p>"},{"location":"02_experiment_details/#alpha-alpha-decay","title":"Alpha (\\(\\alpha\\)) Decay","text":"<p>This type of decay releases a positively charged alpha particle (sometimes represented as \\(^4_2\\alpha\\)), consisting of two protons and two neutrons (a helium nucleus) being ejected from the atom, reducing its atomic number by two. It is also the least penetrating of these forms of radiation and can be stopped by just a few centimeters of air, but it has the power to be the most ionizing and destructive of the types we'll cover here. </p> <p>Because of the low penetrating power of alpha particles, they are generally only harmful to life if the radioactive source is swallowed, inhaled, or held closely to the body for prolonged periods of time.</p> <p>NOTE: Don't do that.</p>"},{"location":"02_experiment_details/#beta-beta-decay","title":"Beta (\\(\\beta\\)) Decay","text":"<p>This type of decay releases a beta particle, which can either be a high-speed electron (\\(\\beta^-\\) or beta minus decay), or its antimatter counterpart the positron (\\(\\beta^+\\) or beta plus decay). \\(\\beta^-\\) decay occurs when a neutron transforms into a proton, releasing an electron and an antineutrino to conserve charge, while \\(\\beta^+\\) decay occurs when a proton transforms into a neutron, releasing a neutrino and positron to conserve charge. So, an atom which undergoes beta decay can can gain or lose one atomic number depending on whether it is \\(\\beta^-\\) or \\(\\beta^+\\), but will have an unchanged mass number.</p> <p>This type of radiation is in between the other two in terms of both ionization and penetrative power. It is able to pass several millimeters into aluminum, but is generally considered a mild hazard. If exposed to beta radiation for long enough however, it is possible to develop burns similar to those caused by heat. As with alpha radiation, these effects can be exacerbated if the source is swallowed, inhaled, or held for long periods of time.</p>"},{"location":"02_experiment_details/#gamma-gamma-decay","title":"Gamma (\\(\\gamma\\)) Decay","text":"<p>Unlike the other two, gamma decay doesn't release a particle with mass, instead releasing electromagnetic radiation in the form of a chargeless photon of light. Gamma radiation differs from other more familiar forms of light (such as visible light or x-rays), in that it has the shortest wavelengths and thus the highest energies of light. Gamma radiation has many possible sources, but in particle physics it normally occurs after a nucleus undergoes either alpha or beta decay. This decay leaves the nucleus in an excited state, and when the nucleons transition to a lower energy state, it releases one of these high energy photons.</p> <p>This transition is much like the process through which the more common types of light are emitted, where an electron will transition between energy levels, releasing a photon in the process. However, this transition involves the strong nuclear force rather than the electromagnetic, producing a photon orders of magnitude more energetic. The typical photon released through electronic relaxation will be in the eV range, usually less than 100eV, while the typical photon released from an atomic nucleus will range from around 1keV to 10MeV of energy.</p> <p>Gamma radiation has the most ability to penetrate materials but is also the least ionizing of these three types of radiation. Natural exposure to gamma radiation is in the range of 1-4 mSv (milli-Seivert) per year, while the lower end of exposure which can begin to cause harmful effects such as cancer are estimated to be around 100 mSv. For reference, your typical chest x-ray will deliver around 5-8 mSv, and a PET/CT scan will deliver between 14-32 mSv. At 1 Sv, the effects of acute radiation sickness can start to be observed, and the dosage at which approximately 50% of those exposed to it will die (the \\(LD_{50}\\)) sits around 3-5 Sv. </p>"},{"location":"02_experiment_details/#instrumentation","title":"Instrumentation","text":"<p>Now that we've gone over the different types of radiation, let's go over how we can detect gamma decay experimentally, and then how we can use these detections to calibrate our instruments and determine the properties of an unknown isotope.</p>"},{"location":"02_experiment_details/#scintillator","title":"Scintillator","text":"<p>The scintillator is the first step in our instrumentation. These devices utilize the properties of certain materials to luminesce when excited by radiation, causing them to re-emit light at a lower and more easily detectable wavelength. For gamma ray detection, photons Compton scatter off of electrons in the structure of the scintillator. </p> <p>Compton scattering describes the effect where high-energy photons interact with loosely-bound valence shell electrons, giving them enough energy to be released from their atoms and ionizing the atom in the process. Those free electrons can then scatter off of other electrons, spreading the energy of the initial gamma ray across multiple electrons. As each of these electrons relax and are recaptured by the ionized atoms, they then release photons at a lower energy.</p> <p>It is by this process that one high energy gamma ray can be turned into several lower energy photons which can then be detected using the second instrument in the experiment.</p>"},{"location":"02_experiment_details/#photomultiplier-tube-pmt","title":"Photomultiplier Tube (PMT)","text":"<p>A PMT is an incredibly sensitive photon detector, and they are normally designed to detect light specifically in the ultraviolet, visible, and near-infrared ranges of the electromagnetic spectrum (which is why we need the scintillator to step-down our high gamma energies).</p> <p>They are typically constructed using an evacuated glass housing with a photocathode on one end, which is engineered to use the photoelectric effect. This again uses energy from light to release electrons, but now in the presence of an electric field. The electric field then accelerates the released electrons towards the back of the PMT, and along the way the electrons will strike against arrays of dynodes.</p> <p>Each dynode has a higher potential difference (voltage) than the previous one, and they are designed so that with each electron that strikes them, they release several more. This causes an exponential cascade of electrons to flow through the system until they finally reach the anode at the end of the PMT. Here, the cascade of electrons results in a current which can be detected using a device such as an oscilloscope or a spectrometer, and the results can then be recorded. In this experiment, a spectrometer was used to record the data.</p>"},{"location":"02_experiment_details/#spectrometer","title":"Spectrometer","text":"<p>\"Spectrometer\" is a broad class of scientific instruments which can be used for detecting and measuring the spectral components of light. The one used for this experiment was a Universal Computer Spectrometer (UCS). The UCS was the final component in the detection chain and serves as the interface between the analog signal produced by the PMT and the digital data we will analyze. This type of spectrometer is called \"universal\" as it can be configured for a wide range of radiation detection experiments, and \"computer\" as it can be integrated with a digital system capable of binning, processing, and storing pulse data. </p> <p>It works by monitoring the pulses of current generated at the anode of the PMT. Each pulse corresponds to a single detected photon event detected by the scintillator and converted to a current by the PMT. The one used in this experiment contained 2048 channels, with higher channels corresponding to higher detected currents.</p>"},{"location":"02_experiment_details/#data-analysis","title":"Data Analysis","text":"<p>The next step in this process is to take the data from the radioactive sources and feed them into a computer using software. As decay events occur in relation to the associated element's half life, it is necessary to run the detection software for several minutes for each element in order to collect as much data as possible. Without running the data for enough time, it may become difficult or impossible to distinguish the signal from the noise, resulting in a larger margin of error.</p> <p>After an event is measured by a specific channel, that channel's count number is increased by one. This eventually results in noticeable peaks which correspond with the given isotope's emission energy. </p> <p>However, due to the steps of the scintillator and PMT, it is not possible to immediately directly correlate a specific channel with a specific emission energy. It is because of the steps required to be able to detect the gamma rays in the first place that we must also perform significant data analysis to associate channel numbers with emission energies. The resulting relationship between channel numbers and emission energies is linear. Each channel should correspond to a specific range of gamma energies.</p> <p>This system is further limited by the geometry of the setup. The radioactive sources are placed underneath the detector and then radiate equally in every direction, meaning only a fraction will interact optimally with the detector. Some of these emissions will hit the detector with a glancing blow, meaning that they'll have less detected energy than the others, while a small amount of photons actually will go straight into the detector but will then have much of their energy reflected directly out. This distribution of energies will result in a Gaussian curve, where the center of the curve will correspond to the average detected energies of the emitted particles. It will also result in other features which will become visible when plotted which we will go over in the next section, called the Compton continuum and the Compton edge.</p> <p>So, in order to determine what element our unknown radioactive source is, it will be necessary to first perform a curve fit for each one of the peaks detected, and then use the known values for their emissions to perform a second curve fit to relate the channel numbers with their actual energies. </p> <p>Let's get going, then! Click here to continue to the next section where we'll get started by isolating the photopeaks in our data.</p>"},{"location":"03_isolating_peaks/","title":"Initial Data Plotting","text":"<p>For this section, let's first see the entire process for selecting out the data for a single file so that it can be generalized and applied to all of our data. Just as an example, I'll be demonstrating the process using the <code>Co60.csv</code> file.</p> <p>Before we can get started plotting our data, we'll want to import the modules which will be used. In the first cell of your Jupyter Notebook, add the import statements:</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import curve_fit\nfrom scipy.signal import find_peaks\nfrom scipy.stats import linregress, chi2\n</code></pre> <p>As a last step before plotting, we'll want to inspect our <code>.csv</code> files to see which rows and columns we're able to use. Here's what the first several lines of the file <code>Co60.csv</code> contain:</p> <p></p> <p>As you can see here, rows 1 through 18 contain extraneous data related to the program settings when the data was collected, such as the voltage, fine and coarse grain values, the time and date that the data was collected, and so on. It isn't until row 23 that we start getting actual data points, with row 22 telling us the column names. We can also see that only the first and third columns (Channel &amp; Counts) contain data, with the second column (Energy) being empty. These facts hold true across all of our files, so we can skip the same rows and only use the same columns across all of our data.</p> <p>For much of our data, it will also be easier to find our peaks if we set the y-axis on a logarithmic scale. Let's get started by creating a method which will load and plot our data when given a file path, and which will also have an option to allow us to control how the y-axis is scaled:</p> <pre><code>def plot_data(isotope, y_log=True):\n    data = pd.read_csv(f'raw-data/{isotope}.csv', skiprows=21, usecols=[0,2])\n    # Assign axes and names\n    x_axis = data.iloc[:,0]\n    x_name = data.columns[0]\n\n    y_axis = data.iloc[:,1]\n    y_name = data.columns[1]\n\n    # Create plot\n    plt.scatter(x_axis, y_axis, s=1)\n    plt.xlabel(x_name)\n    plt.ylabel(y_name)\n    plt.title(f\"{isotope} raw data\")\n    plt.savefig(f\"{isotope}_raw_data.png\")\n    if y_log:\n        plt.yscale('log')\n    plt.show()\n\n    return data\n</code></pre> <p>You can then use this method along with a filepath to create a plot of the recorded data:</p> <pre><code>plot_data(\"Co60.csv\", y_log=True)\n</code></pre> <p>Output:</p> <p></p>"},{"location":"03_isolating_peaks/#interpreting-the-plot","title":"Interpreting the Plot","text":"<p>In order to properly calibrate our data, it's necessary that we fully understand what the raw data is telling us. In this case, it's important to know first that Cobalt-60 has two peak emission spectra: one at 1.175 MeV, and another at 1.333 MeV. However, in this plot, there appear to be at least 3 separate peaks: 1 on the far left, and 2 on the far right of the plot, and 2 bumps which could possibly be considered peaks between them. So, how do we know which ones to consider?</p>"},{"location":"03_isolating_peaks/#compton-scattering","title":"Compton Scattering","text":"<p>In gamma spectroscopy, not every gamma photon deposits its full energy into the detector. As mentioned previously, the scintillator steps down the photon energies in a process known as Compton scattering, where the photon transfers its energy to an electron. In this process, it is possible for only a fraction of the photon's energy to be absorbed by the electron it's incident upon, with the total deposited energy being reliant on the scattering angle. Between the leftmost and rightmost peaks in the plot, you can see a gently sloping distribution. This is known as the Compton plateau or Compton continuum.</p> <p>The upper limit of partial energy deposition forms what's called the Compton edge (or Compton cliff): a relatively sharp drop at the high-energy end of the Compton continuum. In the plot for Cobalt-60, this can be seen just before the peaks on the right hand side. The energy of this edge corresponds to the maximum energy that a photon can transfer in a single Compton scattering event, which occurs when it's backscattered \\(180^\\circ\\) - when the photon goes straight up in the detector, deposits a significant fraction of its energy, and is then reflected directly away. The smaller \"bumps\" before the main peaks are not true photopeaks, but part of the backscatter pattern.</p> <p>The far-left peak is most likely the result of backscatter radiation as well. Backscatter peaks arise when gamma photons scatter off of nearby objects, such as the detector housing or lab walls, and then re-enter the detector with significantly reduced energy. These photons can produce a small but distinct peak at lower channels, well below the main Compton continuum. </p> <p>It's important to understand that the Compton edge only shows the maximum for partial energy loss, not the maximum possible energy that can be detected. Past the edge, a photon gets closer to being fully absorbed by the scintillator, meaning everything before the furthest right peaks represents events where the photon is at least partially reflected out of the detector, and the centers of the peaks represent where all of the photon's energy is absorbed by the scintillator and passed on to the PMT. Every true photopeak should be preceded by a Compton continuum and edge. As our photopeaks are so near each other in our Co-60 data, their respective Compton features overlap.</p> <p>Altogether, this plot shows:</p> <ul> <li> <p>A backscatter reflective peak on the far left,</p> </li> <li> <p>A Compton continuum in the mid range,</p> </li> <li> <p>A Compton edge before the two peaks on the right,</p> </li> <li> <p>And finally, the two true photopeaks of Cobalt-60 on the far right.</p> </li> </ul> <p>Now that we understand the features of our plot, let's move forward to selecting our peaks.</p>"},{"location":"03_isolating_peaks/#selecting-the-photopeaks","title":"Selecting the Photopeaks","text":"<p>There are two main methods that can be used to find our peaks: </p> <ol> <li> <p>Using the <code>find_peaks</code> module in <code>scipy</code></p> </li> <li> <p>Visually inspecting the data.</p> </li> </ol> <p>Before attempting either of these methods, let's edit our <code>plot_data</code> function to return the <code>data</code> variable so that it can be saved and used elsewhere. At the end of the function, simply add <code>return data</code>. Then, when you call the function, you can set <code>data</code> to a new variable, turning our function call into:</p> <pre><code>Co_60 = plot_data(\"Co60.csv\", y_log=True)\n</code></pre> <p>Now we can use the <code>Co_60</code> variable to find our peaks. Let's look at the process for using <code>find_peaks</code> first.</p>"},{"location":"03_isolating_peaks/#find_peaks","title":"<code>find_peaks</code>","text":"<p>In order to find our peaks with this method, we'll first want to assign  <code>Co_60</code>'s x- and y-axes to variables so that we can plot them underneath our peak finding. The result that we're looking for is to have one selected point at the top of our two right peaks.</p> <p>The <code>find_peaks</code> module can take as optional parameters: <code>height</code>, <code>threshold</code>, <code>distance</code>, <code>prominence</code>, <code>width</code>, <code>wlen</code>, <code>rel_height</code>, and <code>plateu_size</code>. Locating the peaks will require careful manipulation of these values in order to exclude noise. For more complete descriptions of these parameters, click here to go to the official documentation.</p> <p>Without assigning any of these parameters a value, <code>find_peaks</code> selects indices in the data that are preceded by and followed by smaller values. It returns them along with a dictionary which contains the values it calculates for the optional parameters (heights, thresholds, prominences, etc). To show what this looks like, let's plot our data underneath the found peaks without first changing any parameters:</p> <pre><code>x_values = Co_60.iloc[:,0]\ny_values = Co_60.iloc[:,1]\npeaks, properties = find_peaks(y_values)\nplt.scatter(x_values, y_values, s=1)\nplt.plot(peaks, y_values[peaks], 'x', color='red')\nplt.show()\n</code></pre> <p>Output:</p> <p></p> <p>Each one of the plotted 'x's is being counted as a 'peak'. So, to narrow down our choices, let's start trying to estimate the parameters. Let's try adjusting <code>distance</code>, <code>prominence</code>, and <code>width</code>. The distance argument sets the minimum distance that should exist between two peaks. The <code>prominence</code> argument measures the vertical distance between the top of the peak and the lowest contour line that doesn't enclose a higher peak (as opposed to <code>height</code> which measures the distance from the top of the peak to y=0). The width argument measures the horizontal span of a single peak. If we provide an estimate for these values at <code>150</code>, <code>100</code>, and <code>60</code> respectively, we'll be able to select out the two peaks we want:</p> <pre><code>x_values = Co_60.iloc[:,0]\ny_values = Co_60.iloc[:,1]\npeaks, _ = find_peaks(y_values, distance=150, prominence=100, width=60)\nplt.plot(x_values, y_values)\nplt.plot(peaks, y_values[peaks], 'x', color='red')\nplt.show()\n</code></pre> <p>Output:</p> <p></p> <p>Now, we'll have to save the data around the peaks. This can be done with a <code>for loop</code> where we select a number of points on either side of the peak, extract that portion of the dataset, and store it for later use. We'll also include safeguards to ensure we don't go outside of the bounds of the data:</p> <pre><code>peak_ranges = []\nfor peak in peaks:\n    left=max(0, peak-60)\n    right=min(len(y_values)-1, peak + 60)\n    peak_ranges.append(Co_60.iloc[left:right].copy())\n</code></pre> <p>Each entry in <code>peak_ranges</code> now holds a slice of data centered around one of the detected peaks. We can plot each of these slices to visually confirm that the correct regions were captured:</p> <pre><code>for peak in peak_ranges:\n    plt.scatter(peak.iloc[:,0], peak.iloc[:,1], s=1)\nplt.title('Isolated peaks')\nplt.xlabel('Channels')\nplt.ylabel('Counts')\nplt.show()\n</code></pre> <p>Output:</p> <p></p> <p>This also highlights one of the shortcomings of the <code>find_peaks</code> function. As we can see with the peak on the left, our selection won't necessarily be centered. It found the highest point in the left peak, which happens to be an outlier for the relevant data, and assumes that this point is the center of the peak.</p> <p>You could then set each peak to a new variable so that it can be used in the next section by using:</p> <pre><code>Co_60P1 = peak_ranges[0]\nCo_60P2 = peak_ranges[1]\n</code></pre> <p>While <code>find_peaks</code> is generally very powerful, it requires careful tuning of multiple parameters. It is also possible to run into plots where the peaks that you see can't easily be distinguished from noise using this module, or where it is impossible to set the parameters to include all peaks, such as when two peaks overlap with each other while others are distinct. There are work arounds for these issues, but it may be better to use another method for isolating your peaks depending on which problems you're running into.</p>"},{"location":"03_isolating_peaks/#visual-inspection","title":"Visual inspection","text":"<p>While it may not be programmatically optimized, one of the easier ways to isolate peaks is by eye: simply estimate where the boundaries of the peaks are and use those numbers to splice the plot. If it's off - adjust your numbers until the peaks are as close to centered as you can get them. If you plot your estimates as you go, you will also be contracting what's shown of the x-axis, providing you with new tick marks with less distance between them, allowing you to splice more accurately.</p> <p>Let's try:</p> <pre><code>Co_60P1 = Co_60.iloc[1600:1900].copy()\nplt.scatter(co_peak_one.columns[0], co_peak_one.columns[1], s=1)\nplt.show()\n</code></pre> <p>Output:</p> <p></p> <p>This isn't perfect, but makes it easier to find the appropriate limits. To center the peak, let's use the data range [1680:1815]:</p> <p></p> <p>Nice! Now we can use the same process to isolate our second peak, giving us:</p> <pre><code>Co_60P2 = Co_60.iloc[1850:2025].copy()\nplt.scatter(Co_60P2.iloc[:,0], Co_60P2.iloc[:,1], s=1)\nplt.show()\n</code></pre> <p>Output:</p> <p></p> <p>Now that we have our first peaks isolated, click here to continue on to the next section where we'll learn how to fit our data to curves.</p>"},{"location":"04_fitting_curves/","title":"<code>curve_fit</code>","text":"<p>The parameters that <code>curve_fit</code> works from are given by the official documentation as: <code>f</code>, <code>xdata</code>, <code>ydata</code>, <code>p0</code>, <code>sigma</code>, <code>absolute_sigma</code>, <code>check_finite</code>, <code>bounds</code>, <code>method</code>, <code>jac</code>, <code>full_output</code>, <code>nan_policy</code>, and <code>**kwargs</code>. Only the first three parameters are required: <code>f</code>, <code>xdata</code>, and <code>ydata</code>, but including the fourth, <code>p0</code>, is often essential for guiding the fit, especially when the function is nonlinear or has multiple parameters. <code>p0</code> defaults to all ones if not specified, but this often fails for more complex models. </p> <p>Only these four will be covered here, but feel free to explore the documentation provided if you wish to use everything that <code>curve_fit</code> has to offer.</p> <p>Here, <code>f</code> is our model function. This requires the creation of another function which will be called in <code>curve_fit</code>. It is necessary that the first argument that this function takes is the independent variable, which is the x-axis in the case of our data. The other parameters of this function will be the remaining unknown variables of the equation. </p> <p><code>xdata</code>, and <code>ydata</code> are exactly what they sound like: the data that you're fitting to the model function.</p> <p><code>p0</code> is the initial guess for the unknown variables/parameters of the model function. It is given as an array where every guess is listed in the order that their associated parameters are listed in the function definition (i.e. if the function is: <code>def function(x, a, b)</code>, <code>p0</code> would be <code>[a_estimate, b_estimate]</code>). </p> <p>Let's get started on creating our model function.</p>"},{"location":"04_fitting_curves/#the-gaussian","title":"The Gaussian","text":"<p>The Gaussian (or Normal) Distribution is a common equation that you'll run into in statistical mechanics. It describes a symmetric, bell-shaped curve centered at a mean value, \\(\\mu\\) (mu), with its width determined by the standard deviation, \\(\\sigma\\) (sigma), and its offset above the x-axis given by D (called the y-offset). It has the form:</p> \\[f(x)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}+D\\] <p>In gamma spectroscopy, we are using the Gaussian as a model for how our detected energy counts are spread around the central photopeak. Variations in the emission and detection of our photons have caused the recorded values to \"smear\" into a normal distribution, with the most common value being the center of the curve. Fitting our data to this curve then allows us to extract the value for the central energy, \\(\\mu\\), as well as its margin of error.</p> <p>In our equation, the first term (\\(\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\)) is called the normalization constant. Its purpose is to set the value of the integral of our curve to be equal to 1, meaning 100% of the data fits under the curve, but this term can actually be dropped for our purposes. We can thus set our equation to be equal to:</p> \\[f(x)=A \\cdot e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}+D\\] <p>In this equation:</p> <ul> <li> <p>A controls the height/amplitude of the peak</p> </li> <li> <p>\\(\\mu\\) is the mean value in the center (the energy of the photon)</p> </li> <li> <p>\\(\\sigma\\) relates to the standard deviation/thickness of the \"line\"</p> </li> <li> <p>D is the y-offset.</p> </li> </ul> <p>Let's create a <code>gaussian</code> function which simply returns our equation \\(f(x)\\):</p> <pre><code>def gaussian(x, amplitude, mu, sigma, y_offset):\n    return amplitude * np.exp(-((x-mu)**2) / (2 * sigma**2)) + y_offset\n</code></pre> <p>Additionally, our data will include some peaks which are so close to each other that they actually overlap. Overlapping peaks are common when two gamma emissions have close energies. This can be modelled using the equation:</p> \\[f(x)=A_1 \\cdot e^{-\\frac{(x-\\mu_1)^2}{2\\sigma^2_1}}+A_2 \\cdot e^{-\\frac{(x-\\mu_2)^2}{2\\sigma^2_2}}+...+A_n \\cdot e^{-\\frac{(x-\\mu_n)^2}{2\\sigma^2_n}}+D\\] <p>Where <code>n</code> is given by the number of overlapping peaks. Luckily, our data shouldn't include more than two overlapping peaks, so we can create the second function as:</p> <pre><code>def double_gaussian(x, amp_1, mu_1, sigma_1, amp_2, mu_2, sigma_2, y_offset):\n    return (\n        amp_1 * np.exp(-((x-mu_1)**2) / (2 * sigma_1)**2) \n        + (amp_2 * np.exp(-((x-mu_2)**2) / (2 * sigma_2)**2)) \n        + y_offset\n    )\n</code></pre>"},{"location":"04_fitting_curves/#using-curve_fit","title":"Using <code>curve_fit</code>","text":"<p>Now we can finally use <code>curve_fit</code> to start extracting values from our data. <code>curve_fit</code> can return five different values, <code>popt</code>, <code>pcov</code>, <code>infodict</code>, <code>mesg</code>, and <code>ier</code>, but only the first two are valuable for our purposes. <code>popt</code> is a one dimensional array containing the optimal parameter values, while <code>pcov</code> contains a 2-D array with the approximate covariance of <code>popt</code>. For the uncertainties, only the square roots of the diagonal values of <code>pcov</code> is needed.</p> <p>Let's create a function for each of our gaussian functions which will return <code>popt</code> and <code>pcov</code>. The only difference between these functions will be which equation they call to fit to.</p> <pre><code>def find_gaussian_values(xdata, ydata, p0):\n    return curve_fit(gaussian, xdata, ydata, p0=p0)\n\ndef find_dgaussian_values(xdata, ydata, p0):\n    return curve_fit(double_gaussian, xdata, ydata, p0=p0)\n</code></pre> <p>Next, let's create a function which will take our <code>popt</code> and <code>pcov</code> arrays and use them to create a plot of our data against the line of best fit. It will be able to take an element name and our emission value in order to title each plot. We can also make it capable of plotting either a gaussian or a double gaussian with a simple <code>True</code>/<code>False</code> flag, and then using an <code>if</code>/<code>else</code> tree to differentiate between the two. It will also print out the found parameters and their uncertainties, as well as return our \\(\\mu\\) values and their uncertainties so they can be saved and used later:</p> <pre><code>def plot_best_fit(element, emission_peak, xdata, ydata, popt, pcov, d_gaussian=False):\n    uncertainties = np.sqrt(np.diag(pcov))\n    if not d_gaussian:\n        labels = ['Amplitude', 'Mean', 'Sigma', 'Y-offset']\n    else:\n        labels = ['Amplitude 1', 'Mean 1', 'Sigma 1', \n                  'Amplitude 2', 'Mean 2', 'Sigma 2',\n                  'Y-offset']\n    if not d_gaussian:\n        mu = popt[1]\n        mu_uncertainty = uncertainties[1]\n    else:\n        mu_1, mu_2 = popt[1], popt[4]\n        mu_1_uncertainty, mu_2_uncertainty = uncertainties[1], uncertainties[4]\n\n    plt.scatter(xdata, ydata, label='Data', marker='.', color='blue')\n    if not d_gaussian:\n        plt.plot(xdata, gaussian(xdata, *popt), label='Best fit', color='red')\n        plt.axvline(mu, color='green', linestyle='-.', label=f'$\\mu: {mu:.2f}\\pm{mu_uncertainty:.2f}$')\n    else:\n        plt.plot(xdata, double_gaussian(xdata, *popt), label='Best fit', color='red')\n        plt.axvline(mu_1, color='green', linestyle='-.', label=f'$\\mu_1: {mu_1:.2f}\\pm{mu_1_uncertainty:.2f}$')\n        plt.axvline(mu_2, color='black', linestyle='-.', label=f'$\\mu_2: {mu_2:.2f}\\pm{mu_2_uncertainty:.2f}$')\n\n    plt.title(f'{element}: {emission_peak} Peak')\n    plt.xlabel('Channel')\n    plt.ylabel('Counts')\n    plt.legend()\n    plt.show()\n\n    print('Best fit parameters:')\n    for name, val, err in zip(labels, popt, uncertainties):\n        print(f'{name}: {val:.2f} +/- {err:.2f}')\n\n    if not d_gaussian:\n        return mu, mu_uncertainty\n    else:\n        return mu_1, mu_1_uncertainty, mu_2, mu_2_uncertainty\n</code></pre> <p>With these functions, we can now run our first <code>curve_fit</code>:</p> <pre><code>p0=[175, 1750, 20, 50]\n\nCo_60P1_popt, Co_60P1_pcov = find_gaussian_values(\n    co_peak_one.iloc[:,0].values, \n    co_peak_one.iloc[:,1].values, \n    p0\n    )\n\nCo_60P1_mu, Co_60P1_mu_uncert = plot_best_fit(\n    'Co-60', '1.175 MeV',\n    co_peak_one.iloc[:,0].values, co_peak_one.iloc[:,1].values, \n    Co_60P1_popt, Co_60P1_pcov\n    )\n</code></pre> <p>Output:</p> <p></p> <pre><code>Best fit parameters:\nAmplitude: 160.75 +/- 8.62\nMean: 1747.79 +/- 0.57\nSigma: 33.09 +/- 2.04\nY-offset: 54.67 +/- 9.43\n</code></pre> <p>And for our second peak:</p> <pre><code>p0=[150, 1940, 30, 25]\n\nCo_60P2_popt, Co_60P2_pcov = find_gaussian_values(\n    co_peak_two.iloc[:,0].values, \n    co_peak_two.iloc[:,1].values, \n    p0\n    )\n\nCo_60P2_mu, Co_60P2_mu_uncert = plot_best_fit(\n    'Co-60', '1.333 MeV',\n    co_peak_two.iloc[:,0].values, co_peak_two.iloc[:,1].values, \n    Co_60P2_popt, Co_60P2_pcov\n    )\n</code></pre> <p>Output:</p> <p></p> <pre><code>Best fit parameters:\nAmplitude: 156.96 +/- 3.83\nMean: 1939.07 +/- 0.43\nSigma: 39.02 +/- 1.22\nY-offset: 9.62 +/- 4.18\n</code></pre> <p>Awesome! You've completed your first <code>curve_fit</code> and have found the numbers which we can later associate with the radiation energies. This process has also resulted in us setting the variables <code>Co_60P1_mu</code>, <code>Co_60P1_mu_uncert</code>, <code>Co_60P2_mu</code>, and <code>Co_60P2_mu_uncert</code>. </p> <p>In order to make our work easier later, let's create a new cell at the bottom of our notebook which we'll use to keep a dictionary of all of our elements, their calculated channel numbers and uncertainties, and their associated emission energies (in keV):</p> <pre><code>value_bank = {\n    ('Co-60', Co_60P1_mu, Co_60P1_mu_uncert, 1175),\n    ('Co-60', Co_60P2_mu, Co_60P2_mu_uncert, 1333),\n}\n</code></pre> <p>This is where you'll store variables for each of the remaining files emission peaks, which will be used in the next section. For reference (if you're interested in attempting to find peak fits before continuing to the next section), here is a table with the provided isotopes and the known emission energies of their photopeaks: |Isotope | Energy (keV)                     | |--------|----------------------------------| |Na-22   |511, 1274.54                      | |Mn-54   |834.84                            | |Co-57   |122.06                            | |Co-60   |1173.23, 1332.49                  | |Cd-109  |88.03                             | |Ba-133  |81, 276.4, 302.85, 356.01, 383.85 |</p> <p>After we have performed this process for the remaining files, we'll have successfully extracted the mean channel numbers (\\(\\mu\\)) for every detected emission peak. From there, we can begin the process of fitting our data to a straight line. Click here to continue to the next section where we will look at how to plot all of our data as well as label it and include our margins of error.</p>"},{"location":"05_linregress/","title":"Plotting the Known Data","text":"<p>As mentioned previously, the relationship between the mean channel numbers that we find and the actual emission energy levels should be a linear one. This means that we'll be using the equation of a line:</p> \\[y=mx+b\\] <p>We can now plot our data with the found channel numbers, C, as the y-axis, and the known emission energies, E, as the x-axis, giving us:</p> \\[C=mE+b\\] <p>We should now be able to take our data and fit it to a line with these parameters. After doing this, we should be able to simply plug the mean channel numbers for the peaks of our unknown source into this found equation and compare it to known emission peaks to discover what element it could be.</p> <p>When we're done finding the peaks of all of our data, our <code>value_bank</code> should look like:</p> <pre><code>value_bank = {\n    ('Na-22', Na_22P1_mu, Na_22P1_mu_uncert, 511),\n    ('Na-22', Na_22P2_mu, Na_22P2_mu_uncert, 1274.54),\n    ('Mn-54', Mn_54P1_mu, Mn_54P1_mu_uncert, 834.84),\n    ('Co-57', Co_57P1_mu, Co_57P1_mu_uncert, 122.06),\n    ('Co-60', Co_60P1_mu, Co_60P1_mu_uncert, 1173.23),\n    ('Co-60', Co_60P2_mu, Co_60P2_mu_uncert, 1332.49),\n    ('Cd-109', Cd_109P1_mu, Cd_109P1_mu_uncert, 88.03),\n    ('', Ba_133P1_mu, Ba_133P1_mu_uncert, 81),\n    ('Ba-133', Ba_133P2_mu, Ba_133P2_mu_uncert, 276.4),\n    ('', Ba_133P3_mu, Ba_133P3_mu_uncert, 302.85),\n    ('Ba-133', Ba_133P4_mu, Ba_133P4_mu_uncert, 356.01),\n    ('', Ba_133P5_mu, Ba_133P5_mu_uncert, 383.85),\n} \n</code></pre> <p>NOTE: Only two of the Ba-133 peaks are labelled. This is because they are so close to themselves and other isotopes that their labels would overlap if kept.</p> <p>In order to handle the known peaks separately from our unknown ones, we've also created a separate bank for the peaks from the unknown source:</p> <pre><code>unknown_values = {\n    ('Unknown Peak 1', unknown_P1_mu, unknown_P1_mu_uncert),\n    ('Unknown Peak 2', unknown_P2_mu, unknown_P2_mu_uncert)\n}\n</code></pre> <p>Now, to plot our known peaks, we'll create a <code>for loop</code> to go through <code>value_bank</code> and separate everything into their own arrays. We'll first initialize our arrays and then append the values into them with our loop. As the uncertainties are pretty small, we'll also want to amplify them so that they'll be visible when plotted. This should be fine as long as we note this exaggeration somewhere in our plot.</p> <pre><code>uncertainty_scale = 50\nlabels             = []\ntested_means       = []\ntested_uncertainty = []\nknown_peaks        = []\nfor (label, tested, uncertainty, known) in value_bank:\n    labels.append(label)\n    tested_means.append(tested)\n    tested_uncertainty.append(uncertainty * uncertainty_scale)\n    known_peaks.append(known)\n</code></pre> <p>With our known_peaks and tested_means now separated, we can use <code>scipy</code>'s <code>linregress</code> to calculate the slope, intercept, and their respective margin's of error:</p> <pre><code>result = linregress(known_peaks, tested_means)\nslope         = result.slope\nintercept     = result.intercept\nstderr        = result.stderr\nintercept_err = result.intercept_stderr\n</code></pre> <p>We can now plot our data so far to make sure our data makes sense. If you found the peak values separately and your results show significant deviation from these results, it's possible an error was made that you can now try to find and correct. </p> <p>For plotting the line of best fit, we'll first create a line which uses the calculated slope and intercept values along with <code>np.linspace</code>. We'll add some space on either side of our max and min values to give our data points some visual space. Then we can plot our error bars, display our labels for each data point, and plot our data, the line of best fit, and label our axes:</p> <pre><code>x_line = np.linspace(min(known_peaks)-100, max(known_peaks)+100, 100)\ny_line = slope*x_line + intercept\n\nplt.errorbar(\n    known_peaks, tested_means,\n    yerr=tested_uncertainty,\n    fmt='o', markersize=2, color='black',\n    ecolor='red', elinewidth=1, capsize=2,\n    label='Known Emissions'\n)\n\nfor x, y, label in zip(known_peaks, tested_means, labels):\n    plt.text(x+50, y, label, fontsize=9, ha='left', va='top')\n\nplt.scatter(known_peaks, tested_means, s=1)\nplt.plot(x_line, y_line, label=f'$C=({slope:.2f}\\pm{stderr:.2f})\\cdot E+({intercept:.2f}\\pm {intercept_err:.2f})$')\nplt.xlabel('Emission Energy (keV)')\nplt.ylabel('Measured Channel')\nplt.title('Line of Best Fit')\nplt.legend(title=f'Uncertainties exaggerated {uncertainty_scale}x', fontsize='small')\nplt.show()\n</code></pre> <p>Output:</p> <p></p>"},{"location":"05_linregress/#plotting-the-unknown-isotope","title":"Plotting the Unknown Isotope","text":"<p>In order to find the emission energies for our unknown isotope, we'll have to rearrange our linear equation for E. As \\(C=mE+b\\):</p> \\[E = \\frac{C-b}{m}\\] <p>Now that we have our slope, m, and intercept, b, from using <code>linregress</code>, we can start finding our unknown energy values as well as their uncertainties. We're looking for the uncertainties in the unknown energy as it is possible that when we search gamma tables to try and find our isotope we may get multiple energy results near our central peak. To find the energy uncertainties, we'll have to use error propagation. </p>"},{"location":"05_linregress/#error-propagation","title":"Error Propagation","text":"<p>For a given function:</p> \\[f(x_1, x_2,...,x_n)\\] <p>Where each variable \\(x_i\\) has an uncertainty \\(\\sigma_{x_i}\\), the uncertainty in f, \\(\\sigma_f\\) can be found as:</p> \\[\\sigma_f = \\sqrt{     (\\frac{\\delta f}{\\delta x_1}\\sigma_{x_1}^2) +      (\\frac{\\delta f}{\\delta x_2}\\sigma_{x_2}^2) + ... +      (\\frac{\\delta f}{\\delta x_n}\\sigma_{x_n}^2) }\\] <p>As we're looking for \\(\\sigma_E\\), this means our equation will look like:</p> \\[\\sigma_E = \\sqrt{(\\frac{\\delta E}{\\delta C}\\sigma_C)^2+(\\frac{\\delta E}{\\delta b}\\sigma_b)^2+(\\frac{\\delta E}{\\delta m}\\sigma_m)^2}\\] \\[\\sigma_E = \\sqrt{     (\\frac{1}{m}\\sigma_C)^2 +      (-\\frac{1}{m}\\sigma_b)^2 +     (-\\frac{C-b}{m^2}\\sigma_m)^2 }\\] <p>We can now use all of this information to include our unknown isotopes in the plot as well as return the possible emission energy ranges. First, we'll want to create our new arrays for the labels, the means and uncertainties, and their associated energy values. We can also print out our energy values so that we can later compare the ranges to gamma tables:</p> <pre><code>unknown_labels        = []\nunknown_means         = []\nunknown_uncertainties = []\npredicted_energies    = []\npredicted_uncertainty = []\n\nunknown_values = {\n    ('Unknown Peak 1', unknown_P1_mu, unknown_P1_mu_uncert),\n    ('Unknown Peak 2', unknown_P2_mu, unknown_P2_mu_uncert)\n}\nfor label, tested, uncertainty in unknown_values:\n    unknown_labels.append(label)\n    unknown_means.append(tested)\n    unknown_uncertainties.append(uncertainty)\n\n    # Convert to energy\n    energy = (tested - intercept) /slope\n    energy_uncertainty = np.sqrt(\n        ((uncertainty/slope)**2) +\n        ((-intercept_err/slope)**2) +\n        ((-(tested-intercept)*stderr/(slope**2))**2)\n    )\n    predicted_energies.append(energy)\n    predicted_uncertainty.append(energy_uncertainty)\n    print(f'{label}: {energy:.2f} keV +/- {energy_uncertainty:.2f} keV')\n    print(f'({energy-energy_uncertainty:.2f} keV to {energy+energy_uncertainty:.2f} keV)')\n</code></pre> <p>Output:</p> <pre><code>Unknown Peak 1: 690.28 keV +/- 15.45 keV\n(674.83 keV to 705.73 keV)\nUnknown Peak 2: 1097.36 keV +/- 20.35 keV\n(1077.00 keV to 1117.71 keV)\n</code></pre> <p>As we needed the non-exaggerated uncertainties to accurately calculate the energy ranges, we'll exaggerate them elsewhere and use that new array for plotting. Let's go ahead and plot our error bars and add these data points to our plot:</p> <pre><code>exagg_unk = [u * uncertainty_scale for u in unknown_uncertainties]\n\nplt.errorbar(\n    predicted_energies, unknown_means,\n    yerr=exagg_unk,\n    fmt='o', markersize=2, color='grey',\n    ecolor='green', elinewidth=1, capsize=2,\n    label='Unk. Emissions'\n)\nfor x, y, label in zip(known_peaks, tested_means, labels):\n    plt.text(x+50, y, label, fontsize=9, ha='left', va='top')\nfor x, y, label in zip(predicted_energies, unknown_means, unknown_labels):\n    plt.text(x+50, y, label, fontsize=9, ha='left', va='top')\nplt.scatter(known_peaks, tested_means, s=1)\nplt.scatter(predicted_energies, unknown_means, s=1)\nplt.plot(x_line, y_line, label=f'$C=({slope:.2f}\\pm{stderr:.2f})\\cdot E+({intercept:.2f}\\pm {intercept_err:.2f})$')\nplt.xlabel('Emission Energy (keV)')\nplt.ylabel('Measured Channel')\nplt.title('Line of Best Fit')\nplt.legend(title=f'Uncertainties exaggerated {uncertainty_scale}x', fontsize='small')\nplt.show()\n</code></pre> <p>Output:</p> <p></p>"},{"location":"05_linregress/#finding-matching-isotopes","title":"Finding Matching Isotopes","text":"<p>An important thing to note when trying to find which isotopes our unknown source could potentially be, is that we've never specified that the source contains only one isotope. It's entirely possible that it has two isotopes that have our observed peaks instead. </p> <p>In searching for our source, we'll be using the website https://atom.kaeri.re.kr/old/gamrays.html. Here, we can enter our energy range as well as a half-life, and receive an output of multiple isotopes. As the sources had not been changed in multiple years at UCDenver, we can estimate a half-life of at least a month.</p> <p>Using this tool, our found energy ranges, and an estimated half-life minimum of 30 days, the matches we find for our first peak are:</p> Nuclide Energy (keV) Te-129 695.88 Pm-144 696.49 Nb-94 702.622 <p>And for our second peak, we get the matches:</p> Nuclide Energy (keV) Sn-123 1088.64 Fe-59 1099.25 Te-121 1102.15 Zn-65 1115.55 <p>As this information provides us with no overlapping options, this means that we will have to compare each of the first three options against each of the last four options in order to determine which combination of isotopes our source contained.</p> <p>In order to perform this final analysis, we'll need to perform something known as a \\(\\chi^2\\) (or chi-squared) fit. Click here to continue on to our next section where we will learn how to use such fits to find the quality of our data fits.</p>"},{"location":"06_chi_squared/","title":"What is a \\(\\chi^2\\) Fit?","text":"<p>A \\(\\chi^2\\) (or chi-squared/weighted least squares fit) is a way of fitting a model to data when each point has a different uncertainty. </p> <p>If your data points are \\((O_i, C_i)\\), (where O is your Observation data, and C is your Calculated data) and each \\(O_i\\) has an uncertainty \\(\\sigma_i\\), then the best-fit line minimizes the following quantity:</p> \\[\\chi^2 = \\sum_{i}(\\frac{O_i - C_i}{\\sigma_i})^2\\] <p>Once you calculate \\(\\chi^2\\), you can then calculate the reduced chi-squared statistic:</p> \\[\\chi^2_{red}=\\frac{\\chi^2}{\\nu}=\\frac{\\chi^2}{N-p}\\] <p>Where:</p> <ul> <li> <p>\\(N\\) is the number of data points</p> </li> <li> <p>\\(p\\) is the number of fitted parameters</p> </li> <li> <p>\\(\\nu\\) is the degrees of freedom</p> </li> </ul> <p>In our case, we aren't fitting a curve. We're instead testing how well a pair of known emission values match with our predicted energies based on our calibration line. Since we have uncertainties associated with those predicted energies, a \\(\\chi^2\\) test gives us a rigorous way to evaluate the quality of each potential match. </p> <p>We'll perform a \\(\\chi^2\\) calculation for each possible pairing between a peak-1 candidate and a peak-2 candidate. For each of our possible 12 pairs, we'll compare their known emission energies to our observed values. So, for each pair we will compute:</p> \\[\\chi^2 = (\\frac{E_{obs,1}-E_{obs,1}}{\\sigma_1})^2 + (\\frac{E_{obs,2}-E_{obs,2}}{\\sigma_2})^2\\] <p>We're not fitting any parameters, \\(\\nu\\) will be set to the number of data points alone, giving us:</p> \\[\\chi^2_{red}=\\frac{\\chi^2}{2}\\] <p>The combination with the lowest value for \\(\\chi^2_{red}\\) will be considered the best fit.</p>"},{"location":"06_chi_squared/#implementing-the-chi2-calculation","title":"Implementing the \\(\\chi^2\\) calculation","text":"<p>To automate this process, we can use the following function in Python:</p> <pre><code>def chi_squared(observed, expected, uncertainties):\n    residuals = (observed - expected) / uncertainties\n    return np.sum(residuals**2)\n</code></pre>"}]}