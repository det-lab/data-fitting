{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Data Fitting Lesson","text":"<p>Created by Adrian Fisher</p>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    01_introduction.md # Introduction\n    02_setup.md # Downloading python and Jupyter\n    03_experiment_details.md # Explaining the experiment\n    04_isolating_peaks.md # Getting peaks out of data\n    05_fitting_curves.md # Doing first curve fits\n</code></pre>"},{"location":"01_introduction/","title":"Introduction","text":"<p>Curve fitting is one of the most powerful tools available to us in modern computing. Curve fitting describes the process of matching multiple data points with an equation while finding terms to describe the margins of error and other unknown parameters. </p> <p>In this lesson, we're going to use curve fitting along with gamma spectroscopy data taken at the University of Colorado Denver in order to demonstrate the usefulness of the operation. The data will include 6 radioactive isotopes with known emission spectra as well as a 7th and final unknown isotope. In the process, we will learn how to create a function which can fit a Gaussian curve before using the findings from our fits to find a final line which can help us determine the properties of the unknown isotope. We will also then learn about \\(\\chi^2\\)-fits and use one to determine how well our data fits the solution we find for the unknown isotope.</p> <p>Let's get started - click here to continue on to the next section where we will begin setting up our computers.</p>"},{"location":"02_setup/","title":"Setup","text":"<p>This lesson will be using Python 3 along with several of its more common libraries: <code>scipy</code>, <code>pandas</code>, <code>matplotlib</code>, and <code>numpy</code>. This lesson will also be done using a Jupyter Notebook. </p> <p>First, it'll be necessary to install Python if you don't already have it. You can follow the instructions from python's official website in order to get started. </p> <p>It's recommended to install Jupyter Notebook through <code>pip</code>, so after installing Python you should check that it comes with <code>pip</code> installed. This can be done by running the following commands depending on your operating system:</p> Linux MacOS Windows Command (Check python) python --version python --version py --version Output Python 3.N.N Python 3.N.N Python 3.N.N Command (Check pip) python -m pip --version python -m pip --version py -m pip --version Output pip X.Y.Z from (python 3.N.N) pip X.Y.Z from (python 3.N.N) pip X.Y.Z from (python 3.N.N) <p>You can then use <code>pip</code> to install either <code>JupyterLab</code> or <code>Jupyter Notebook</code> with the command:</p> <pre><code>pip install jupyterlab\n</code></pre> <p>or:</p> <pre><code>pip install notebook\n</code></pre> <p>You can then run them with either:</p> <pre><code>jupyter lab\n</code></pre> <p>or:</p> <pre><code>jupyter notebook\n</code></pre> <p>It should be noted that in order for Jupyter to work you will also be required to have an up-to-date browser. Chrome, Safari, and Firefox are all supported.</p> <p>Running one of these commands will then open Jupyter in a browser. </p> <p>Jupyter will then show you an in-browser version of your file-explorer where you can navigate to create a new project folder to follow along with this lesson. Before doing that, make sure that you also have the necessary libraries installed. Click on <code>New</code> and select <code>Terminal</code> in order to ensure that the libraries are installed in the same location that Jupyter has access to. From this terminal, run the commands:</p> <pre><code>pip install scipy\npip install pandas\npip install matplotlib\npip install numpy\n</code></pre> <p>The <code>scipy</code> library will be used to find our peaks and create our curve fits, <code>pandas</code> will be used for loading the <code>.csv</code> data, <code>matplotlib</code> will be used to plot the data, and <code>numpy</code> will be used for multiple mathematical expressions.</p> <p>Next, create a folder to house your project files, named something like \"data-fitting\". After doing this, download and unzip these raw data files. Then, you can move the \"raw-data\" folder into your project folder. </p> <p>Finally, create a new notebook by clicking on <code>New</code> and <code>Notebook</code> and selecting the kernel - <code>Python 3 (ipykernel)</code>. You can then either name your project or keep it untitled.</p> <p>Now that we're all setup, click here to continue to the next section where we can begin to learn more about the experiment and how it functions before getting started fitting our data.</p>"},{"location":"03_experiment_details/","title":"The Experiment","text":"<p>In this experiment, gamma spectroscopy data was collected from a UCDenver gamma spectroscopy lab. The lab involved taking data using a spectrometer which is fed from a scintillator and a photomultiplier tube (PMT) to record the energy levels emitted by various radioactive sources. Let's go over the types of radioactive decay and describe what the related instruments are doing so that you can have a better understanding of the data that we're looking at when we start plotting it.</p>"},{"location":"03_experiment_details/#radioactive-decay","title":"Radioactive Decay","text":"<p>There are three main types of radioactive decay associated with emissions, alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), and gamma (\\(\\gamma\\)), named in increasing order of their ability to penetrate matter (\\(\\gamma &gt; \\beta &gt; \\alpha\\)). These three types of emissions are notable also for their ability to be separated from each other from inside of an electromagnetic field - meaning they all have different types of charge. </p> <p>Starting from the element bismuth, every element and every isotope is at least slightly radioactive. In other words, there are no stable isotopes after bismuth. From bismuth up, the strong force which holds the nucleus together struggles to reach across the distance of the nucleus, meaning the electric force which wants the positively charged protons to repel each other causes the nucleus to become unstable. For elements lighter than bismuth, every element has at least one stable isotope, but there are still many unstable isotopes such as Carbon-14 or Potassium-40.</p>"},{"location":"03_experiment_details/#alpha-alpha-decay","title":"Alpha (\\(\\alpha\\)) Decay","text":"<p>This type of decay releases a postively charged alpha particle (sometimes represented as \\(^4_2\\alpha\\)), consisting of two protons and two neutrons (a helium nucleus) being ejected from the atom, reducing its atomic number by two. It is also the least penetrating of these forms of radiation and can be stopped by just a few centimeters of air, but it has the power to be the most ionizing and destructive of the types we'll cover here. </p> <p>Because of the low penetrating power of alpha particles, they are generally only harmful to life if the radioactive source is swallowed, inhaled, or held closely to the body for prolonged periods of time.</p> <p>NOTE: Don't do that.</p>"},{"location":"03_experiment_details/#beta-beta-decay","title":"Beta (\\(\\beta\\)) Decay","text":"<p>This type of decay releases a beta particle, which can either be a high-speed electron (\\(\\beta^-\\) or beta minus decay), or its antimatter counterpart the positron (\\(\\beta^+\\) or beta plus decay). \\(\\beta^-\\) decay occurs when a neutron transforms into a proton, releasing an electron and an antineutrino to conserve charge, while \\(\\beta^+\\) decay occurs when a proton transforms into a neutron, releasing a neutrino and positron to conserve charge. So, an atom which undergoes beta decay can can gain or lose one atomic number depending on whether it is \\(\\beta^-\\) or \\(\\beta^+\\), but will have an unchanged mass number.</p> <p>This type of radiation is in between the other two in terms of both ionization and penetrative power. It is able to pass several millimeters into aluminum, but is generally considered a mild hazard. If exposed to beta radiation for long enough however, it is possible to develop burns similar to those caused by heat. As with alpha radiation, these effects can be exacerbated if the source is swallowed, inhaled, or held for long periods of time.</p>"},{"location":"03_experiment_details/#gamma-gamma-decay","title":"Gamma (\\(\\gamma\\)) Decay","text":"<p>Unlike the other two, gamma decay doesn't release a particle with mass, instead releasing electromagnetic radiation in the form of a chargeless photon of light. Gamma radiation differs from other more familiar forms of light (such as visible light or x-rays), in that it has the shortest wavelengths and thus the highest energies of light. Gamma radiation has many possible sources, but in particle physics it normally occurs after a nucleus undergoes either alpha or beta decay. This decay leaves the nucleus in an excited state, and when the nucleons transition to a lower energy state, it releases one of these high energy photons.</p> <p>This transition is much like the process through which the more common types of light are emitted, where an electron will transition between energy levels, releasing a photon in the process. However, this transition involves the strong nuclear force rather than the electromagnetic, producing a photon orders of magnitude more energetic. The typical photon released through electronic relaxation will be in the eV range, usually less than 100eV, while the typical photon released from an atomic nucleus will range from around 1keV to 10MeV of energy.</p> <p>Gamma radiation has the most ability to penetrate materials but is also the least ionizing of these three types of radiation. Natural exposure to gamma radiation is in the range of 1-4 mSv (milli-Seivert) per year, while the lower end of exposure which can begin to cause harmful effects such as cancer are estimated to be around 100 mSv. For reference, your typical chest x-ray will deliver around 5-8 mSv, and a PET/CT scan will deliver between 14-32 mSv. At 1 Sv, the effects of acute radiation sickness can start to be observed, and the dosage at which approximately 50% of those exposed to it will die (the \\(LD_{50}\\)) sits around 3-5 Sv. </p>"},{"location":"03_experiment_details/#instrumentation","title":"Instrumentation","text":"<p>Now that we've gone over the different types of radiation, let's go over how we can detect gamma decay experimentally, and then how we can use these detections to calibrate our instruments and determine the properties of an unknown isotope.</p>"},{"location":"03_experiment_details/#scintillator","title":"Scintillator","text":"<p>The scintillator is the first step in our instrumentation. These devices utilize the properties of certain materials to luminesce when excited by radiation, causing them to re-emit light at a lower and more easily detectable wavelength. For gamma ray detection, photons Compton scatter off of electrons in the structure of the scintillator. </p> <p>Compton scattering describes the effect where high-energy photons interact with loosely-bound valence shell electrons, giving them enough energy to be released from their atoms and ionizing the atom in the process. Those free electrons can then scatter off of other electrons, spreading the energy of the inital gamma ray across multiple electrons. As each of these electrons relax and are recaptured by the ionized atoms, they then release photons at a lower energy.</p> <p>It is by this process that one high energy gamma ray can be turned into several lower energy photons which can then be detected using the second instrument in the experiment.</p>"},{"location":"03_experiment_details/#photomultiplier-tube-pmt","title":"Photomultiplier Tube (PMT)","text":"<p>A PMT is an incredibly sensitive photon detector, and they are normally designed to detect light specifically in the ultraviolet, visible, and near-infrared ranges of the electromagnetic spectrum (which is why we need the scintillator to step-down our high gamma energies).</p> <p>They are typically constructed using an evacuated glass housing with a photocathode on one end, which is engineered to use the photoelectric effect. This again uses energy from light to release electrons, but now in the presence of an electric field. The electric field then accelerates the released electrons towards the back of the PMT, and along the way the electrons will strike against arrays of dynodes.</p> <p>Each dynode has a higher potential difference (voltage) than the previous one, and they are designed so that with each electron that strikes them, they release several more. This causes an exponential cascade of electrons to flow through the system until they finally reach the anode at the end of the PMT. Here, the cascade of electrons results in a current which can be detected using a device such as an oscilloscope or a spectrometer, and the results can then be recorded. In this experiment, a spectrometer was used to record the data.</p>"},{"location":"03_experiment_details/#spectrometer","title":"Spectrometer","text":"<p>\"Spectrometer\" is a broad class of scientific instruments which can be used for detecting and measuring the spectral components of light. The one used for this experiment was a Universal Computer Spectrometer (UCS). The UCS was the final component in the detection chain and serves as the interface between the analog signal produced by the PMT and the digital data we will analyze. This type of spectrometer is called \"universal\" as it can be configured for a wide range of radiation detection experiments, and \"computer\" as it can be integrated with a digital system capable of binning, processing, and storing pulse data. </p> <p>It works by monitoring the pulses of current generated at the anode of the PMT. Each pulse corresponds to a single detected photon event detected by the scintillator and converted to a current by the PMT. The one used in this experiment contained 2048 channels, with higher channels corresponding to higher detected currents.</p>"},{"location":"03_experiment_details/#data-analysis","title":"Data Analysis","text":"<p>The next step in this process is to take the data from the radioactive sources and feed them into a computer using software. As decay events occur in relation to the associated element's half life, it is necessary to run the detection software for several minutes for each element in order to collect as much data as possible. Without running the data for enough time, it may become difficult or impossible to distinguish the signal from the noise, resulting in a larger margin of error.</p> <p>After an event is measured by a specific channel, that channel's count number is increased by one. This eventually results in noticeable peaks which correspond with the given isotope's emission energy. </p> <p>However, due to the steps of the scintillator and PMT, it is not possible to immediately directly correlate a specific channel with a specific emission energy. It is because of the steps required to be able to detect the gamma rays in the first place that we must also perform significant data analysis to associate channel numbers with emission energies. The resulting relationship between channel numbers and emission energies is linear. Each channel should correspond to a specific range of gamma energies.</p> <p>This system is further limited by the geometry of the setup. The radioactive sources are placed underneath the detector and then radiate equally in every direction, meaning only a fraction will interact optimally with the detector. Some of these emissions will hit the detector with a glancing blow, meaning that they'll have less detected energy than the others, while a small amount of photons actually will go straight into the detector but will then have much of their energy reflected directly out. This distribution of energies will result in a Gaussian curve, where the center of the curve will correspond to the average detected energies of the emitted particles. It will also result in other features which will become visible when plotted which we will go over in the next section, called the Compton continuum and the Compton edge.</p> <p>So, in order to determine what element our unknown radioactive source is, it will be necessary to first perform a curve fit for each one of the peaks detected, and then use the known values for their emissions to perform a second curve fit to relate the channel numbers with their actual energies. </p> <p>Let's get going, then! Click here to continue to the next section where we'll get started by isolating the photopeaks in our data.</p>"},{"location":"04_isolating_peaks/","title":"Initial Data Plotting","text":"<p>For this section, let's first see the entire process for selecting out the data for a single file so that it can be generalized and applied to all of our data. Just as an example, I'll be demonstrating the process using the <code>Co60.csv</code> file.</p> <p>Before we can get started plotting our data, we'll want to import the modules which will be used. In the first cell of your Jupyter Notebook, add the import statements:</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import curve_fit\nfrom scipy.signal import find_peaks\n</code></pre> <p>As a last step before plotting, we'll want to inspect our <code>.csv</code> files to see which rows and columns we're able to use. Here's what the first several lines of the file <code>Co60.csv</code> contain:</p> <p></p> <p>As you can see here, rows 1 through 18 contain extraneous data related to the program settings when the data was collected, such as the voltage, fine and coarse grain values, the time and date that the data was collected, and so on. It isn't until row 23 that we start getting actual data points, with row 22 telling us the column names. We can also see that only the first and third columns (Channel &amp; Counts) contain data, with the second column (Energy) being empty. These facts hold true across all of our files, so we can skip the same rows and only use the same columns across all of our data.</p> <p>For much of our data, it will also be easier to find our peaks if we set the y-axis to use a logarithmic scale. Let's get started by creating a method which will load and plot our data when given the file path, and which will also have an option to allow us to control how the y-axis is scaled:</p> <pre><code>def plot_data(filepath, y_log=True):\n    data = pd.read_csv(filepath, skiprows=21, usecols=[0,2])\n    # Remove \"raw-data/\" and \".csv\" for naming\n    filename = filepath[9:-4]\n    # Assign axes and names\n    x_axis = data.iloc[:,0]\n    x_name = data.columns[0]\n\n    y_axis = data.iloc[:,1]\n    y_name = data.columns[1]\n\n    # Create plot\n    plt.scatter(x_axis, y_axis, s=1)\n    plt.xlabel(x_name)\n    plt.ylabel(y_name)\n    plt.title(f\"{filename} raw data\")\n    plt.savefig(f\"{filename}_raw_data.png\")\n    if y_log:\n        plt.yscale('log')\n    plt.show()\n</code></pre> <p>You can then use this method along with a filepath to create a plot of the recorded data:</p> <pre><code>plot_data(\"raw-data/Co60.csv\", y_log=True)\n</code></pre> <p>Output:</p> <p></p>"},{"location":"04_isolating_peaks/#interpretting-the-plot","title":"Interpretting the Plot","text":"<p>In order to properly calibrate our data, it's necessary that we fully understand what the raw data is telling us. In this case, it's important to know first that Cobalt-60 has two peak emission spectra: one at 1.175 MeV, and another at 1.333 MeV. However, in this plot, there appear to be at least 3 separate peaks: 1 on the far left, and 2 on the far right of the plot, and 2 bumps which could possibly be considered peaks between them. So, how do we know which ones to consider?</p>"},{"location":"04_isolating_peaks/#compton-scattering","title":"Compton Scattering","text":"<p>In gamma spectrscopy, not every gamma photon deposits its full energy into the detector. As mentioned previously, the scintillator steps down the photon energies in a process known as Compton scattering, where the photon transfers its energy to an electron. In this process, it is possible for only a fraction of the photon's energy to be absorbed by the electron it's incident upon, with the total deposited energy being reliant on the scattering angle. Between the leftmost and rightmost peaks in the plot, you can see a gently sloping distribution. This is known as the Compton plateau or Compton continuum.</p> <p>The upper limit of partial energy deposition forms what's called the Compton edge (or Compton cliff): a relatively sharp drop at the high-energy end of the Compton continuum. In the plot for Cobalt-60, this can be seen just before the peaks on the right hand side. The energy of this edge corresponds to the maximum energy that a photon can transfer in a single Compton scattering event, which occurs when it's backscattered \\(180^\\circ\\) - when the photon goes straight up in the detector, deposits a significant fraction of its energy, and is then reflected directly away. The smaller \"bumps\" before the main peaks are not true photopeaks, but part of the backscatter pattern.</p> <p>The far-left peak is most likely the result of backscatter radiation as well. Backscatter peaks arise when gamma photons scatter off of nearby objects, such as the detector housing or lab walls, and then re-enter the detector with significantly reduced energy. These photons can produce a small but distinct peak at lower channels, well below the main Compton continuum. </p> <p>It's important to understand that the Compton edge only shows the maximum for partial energy loss, not the maximum possible energy that can be detected. Past the edge, a photon gets closer to being fully absorbed by the scintillator, meaning everything before the furthest right peaks represents events where the photon is at least partially reflected out of the detector, and the centers of the peaks represent where all of the photon's energy is absorbed by the scintillator and passed on to the PMT. Every true photopeak should be preceeded by a Compton continuum and edge. As our photopeaks are so near each other in our Co-60 data, their respective Compton features overlap.</p> <p>Altogether, this plot shows:</p> <ul> <li> <p>A backscatter reflective peak on the far left,</p> </li> <li> <p>A Compton continuum in the mid range,</p> </li> <li> <p>A Compton edge before the two peaks on the right,</p> </li> <li> <p>And finally, the two true photopeaks of Cobalt-60 on the far right.</p> </li> </ul> <p>Now that we understand the features of our plot, let's move forward to isolating our peaks.</p>"},{"location":"04_isolating_peaks/#isolating-the-photopeaks","title":"Isolating the Photopeaks","text":"<p>There are two main methods that can be used to find our peaks: </p> <ol> <li> <p>Using the <code>find_peaks</code> module</p> </li> <li> <p>Visually inspecting the data.</p> </li> </ol> <p>Before attempting either of these methods, let's edit our <code>plot_data</code> function to return the <code>data</code> variable so that we can manipulate it elsewhere. At the end of the function, simply add <code>return data</code>. Then, when you call the function, you can set <code>data</code> to a new variable, turning our function call into:</p> <pre><code>cobalt = plot_data(\"raw-data/Co60.csv\", y_log=True)\n</code></pre> <p>Now we can use the <code>cobalt</code> variable to find our peaks. Let's start by demonstrating how to use <code>find_peaks</code>.</p>"},{"location":"04_isolating_peaks/#find_peaks","title":"<code>find_peaks</code>","text":"<p>In order to automatically find our peaks, we'll first want to assign  <code>cobalt</code>'s x- and y-axes to variables so that we can plot them again along with our peaks. The result that we're looking for is to have one selected point at the top of our two right peaks.</p> <p>The <code>find_peaks</code> module can take as optional parameters: height, threshold, distance, prominence, width, wlen, rel_height, and plateu_size. Locating the peaks will require careful manipulation of these values in order to exclude noise. For more complete descriptions of these parameters, click here to go to the official documentation.</p> <p>Without assigning any of these parameters a value, <code>find_peaks</code> selects indices in the data that are preceeded by and followed by smaller values. It returns them along with a dictionary which contains the values it calculated for the optional parameters (heights, thresholds, prominences, etc). To show what this looks like, let's plot our data without first trying to optimize to find our peaks:</p> <pre><code>x_values = cobalt.iloc[:,0] # Select first column\ny_values = cobalt.iloc[:,1] # Select second column\npeaks, properties = find_peaks(y_values)\nplt.scatter(x_values, y_values, s=1)\nplt.plot(peaks, y_values[peaks], 'x', color='red')\nplt.show()\n</code></pre> <p>Output:</p> <p></p> <p>Each one of the plotted 'x's is being counted as a 'peak'. So, to narrow down our choices, let's start trying to estimate the other arguments. Let's try adjusting <code>distance</code>, <code>prominence</code>, and <code>width</code>. The distance argument sets the minimum distance that should exist between two peaks. The prominence argument measures the vertical distance between the top of the peak and the lowest contour line that doesn't enclose a higher peak (as opposed to height which measures the distance from the top of the peak to y=0). The width argument measures the horizontal span of a single peak. Let's estimate these values at <code>150</code>, <code>100</code>, and <code>60</code> respectively:</p> <pre><code>x_values = cobalt.iloc[:,0]\ny_values = cobalt.iloc[:,1]\npeaks, _ = find_peaks(y_values, distance=150, prominence=100, width=60)\nplt.plot(x_values, y_values)\nplt.plot(peaks, y_values[peaks], 'x', color='red')\nplt.show()\n</code></pre> <p>Output:</p> <p></p> <p>Now, we'll have to save the data around the peaks. This can be done with a for loop where we select a number of points on either side of the peak, extract that portion of the dataset, and store it for later use. We'll also include safeguards to ensure we don't go outside of the bounds of the data:</p> <pre><code>peak_ranges = []\nfor peak in peaks:\n    left=max(0, peak-60)\n    right=min(len(y_values)-1, peak + 60)\n    peak_ranges.append(cobalt.iloc[left:right].copy())\n</code></pre> <p>Each entry in <code>peak_ranges</code> now holds a slice of data centered around one of the detected peaks. We can plot each of these slices to visually confirm that the correct regions were captured:</p> <pre><code>for peak in peak_ranges:\n    plt.scatter(peak.iloc[:,0], peak.iloc[:,1], s=1)\nplt.title('Isolated peaks')\nplt.xlabel('Channels')\nplt.ylabel('Counts')\nplt.show()\n</code></pre> <p>Output:</p> <p></p> <p>You could then set each peak to a new variable so that it can be used in the next section by using:</p> <pre><code>co_peak_one = peak_ranges[0]\nco_peak_two = peak_ranges[1]\n</code></pre> <p>While <code>find_peaks</code> is generally very powerful, it requires careful tuning of multiple parameters. It is also possible to run into plots where the peaks that you see can't easily be distinguished from noise using this module, or where it is impossible to set the parameters to include all peaks, such as when two peaks overlap with each other while others are distinct. For these instances, it may be better to use another method for isolating your peaks.</p>"},{"location":"04_isolating_peaks/#visual-inspection","title":"Visual inspection","text":"<p>While it may not be programmatically optimized, one of the easier ways to isolate peaks is by eye: simply estimate where the boundaries of the peaks are and use those numbers to splice the plot. If it's off - adjust your numbers until the peaks are as close to centered as you can get them. If you plot your estimates as you go, you will also be contracting what's shown of the x-axis, providing you with new tick marks which can help you splice more accurately.</p> <p>Let's try:</p> <pre><code>co_peak_one = cobalt.iloc[1600:1900].copy()\nplt.scatter(co_peak_one.columns[0], co_peak_one.columns[1], s=1)\nplt.show()\n</code></pre> <p>Output:</p> <p></p> <p>This isn't perfect, but makes it easier to find the appropriate limits. To center the peak, let's use the data range [1680:1815]:</p> <p></p> <p>Nice! Now we can use the same process to isolate our second peak, giving us:</p> <pre><code>co_peak_two = cobalt.iloc[1850:2025].copy()\nplt.scatter(co_peak_two.iloc[:,0], co_peak_two.iloc[:,1], s=1)\nplt.show()\n</code></pre> <p>Output:</p> <p></p> <p>Now that we have our first peaks isolated, click here to continue on to the next section where we'll learn how to fit our data to curves.</p>"},{"location":"05_fitting_curves/","title":"The Gaussian","text":"<p>Now that we have isolated our peak data, we can create a function which will help us find the parameters which describe it. For this, we'll first need to understand the equation that relates to it, here known as a Gaussian (or Normal) Distribution, which has the form:</p> \\[f(x)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}+D\\] <p>A Gaussian distribution describes a symmetric, bell-shaped curve centered at a mean value, \\(\\mu\\) (or mu), with its width determined by the standard deviation, \\(\\sigma\\) (or sigma), and its offset above the x-axis given by D (called the y-offset). </p> <p>In gamma spectroscopy, we are using the Gaussian as a model for how our detected energy counts are spread around the central photopeak. Variations in the emission and detection of our photons have caused the recorded values to \"smear\" into a normal distribution, with the most common value being the center of the curve. Fitting our data to this curve then allows us to extract the value for the central energy, \\(\\mu\\), as well as its margin of error.</p> <p>In our equation, the first term (\\(\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\)) is called the normalization constant. Its purpose is to set the value of the integral of our curve to be equal to 1, meaning 100% of the data fits under the curve, but this term can actually be dropped for our purposes. We can thus set our equation to be equal to:</p> \\[f(x)=A \\cdot e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}+D\\] <p>In this equation:</p> <ul> <li> <p>A controls the height/amplitude of the peak</p> </li> <li> <p>\\(\\mu\\) is the mean value in the center (the energy of the photon)</p> </li> <li> <p>\\(\\sigma\\) relates to the standard deviation</p> </li> <li> <p>D is the y-offset.</p> </li> </ul> <p>In order to get started using <code>curve_fit</code>, we'll first have to create a function for this equation which we will then be able to use later. So, let's create a <code>gaussian</code> function which simply returns our equation \\(f(x)\\):</p> <pre><code>def gaussian(x, amplitude, mu, sigma, y_offset):\n    return amplitude * np.exp(-((x-mu)**2) / (2 * sigma**2)) + y_offset\n</code></pre> <p>Additionally, our data will include some peaks which are so close to each other that they actually overlap. Overlapping peaks are common when two gamma emissions have close energies. This can be modelled using the equation:</p> \\[f(x)=A_1 \\cdot e^{-\\frac{(x-\\mu_1)^2}{2\\sigma^2_1}}+A_2 \\cdot e^{-\\frac{(x-\\mu_2)^2}{2\\sigma^2_2}}+...+A_n \\cdot e^{-\\frac{(x-\\mu_n)^2}{2\\sigma^2_n}}+D\\] <p>Where <code>n</code> is given by the number of overlapping peaks. Luckily, our data shouldn't include more than two overlapping peaks, so we can create the second function as:</p> <pre><code>def double_gaussian(x, amp_1, mu_1, sigma_1, amp_2, mu_2, sigma_2, y_offset):\n    return (\n        amp_1 * np.exp(-((x-mu_1)**2) / (2 * sigma_1)**2) \n        + (amp_2 * np.exp(-((x-mu_2)**2) / (2 * sigma_2)**2)) \n        + y_offset\n    )\n</code></pre>"}]}